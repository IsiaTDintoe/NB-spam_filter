{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Spam Filter with Naive Bayes from scratch\n",
    "\n",
    "In this project, we're going to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm from scratch in order to learn how the algorithms works beneath the surface. Our goal is to write a program that successfully classifies new messages with an accuracy greater than 80% â€” so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "We'll start by reading in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sms_spam = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'SMS'])\n",
    "\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get some information about our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Label   5572 non-null   object\n",
      " 1   SMS     5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "sms_spam.info() # get some information on our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have any missing values. Let's check if we have duplicates and remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for duplicates\n",
    "sms_spam.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5169, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove duplicate\n",
    "sms_spam = sms_spam.drop_duplicates(keep='first')\n",
    "print(sms_spam.shape)\n",
    "sms_spam.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find out what percentage of the messages are spam and what percentage are ham (\"ham\" means non-spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.87367\n",
       "spam    0.12633\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_spam['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's visualise the Label column\n",
    "import matplotlib.pyplot as plt\n",
    "plt.pie(sms_spam['Label'].value_counts(), labels=['ham', 'spam'], autopct=\"%0.2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that about 87% of the messages are ham, and the remaining 13% are spam. This sample looks representative, since in practice most messages that people receive are ham. Also, this means that the dataset is imbalanced, were one classification is more represented than the other one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Test Set\n",
    "\n",
    "We're now going to split our dataset into a training and a test set, where the training set accounts for 80% of the data, and the test set for the remaining 20%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4135, 2)\n",
      "(1034, 2)\n"
     ]
    }
   ],
   "source": [
    "# Randomize the dataset\n",
    "data_randomized = sms_spam.sample(frac=1, random_state=1)\n",
    "\n",
    "# Calculate index for split\n",
    "training_test_index = round(len(data_randomized) * 0.8)\n",
    "\n",
    "# Training/Test split\n",
    "training_set = data_randomized[:training_test_index].reset_index(drop=True)\n",
    "test_set = data_randomized[training_test_index:].reset_index(drop=True)\n",
    "\n",
    "print(training_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now analyze the percentage of spam and ham messages in the training and test sets. We expect the percentages to be close to what we have in the full dataset, where about 87% of the messages are ham, and the remaining 13% are spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.879565\n",
       "spam    0.120435\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.850097\n",
       "spam    0.149903\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results look good, as both classes are well represented similarly from the original dataset. That's awesome! Now we're moving to cleaning the dataset.\n",
    "\n",
    "## Data Cleaning\n",
    "\n",
    "To make all calculations easier of the probabilities required by the algorithm, we'll first need to perform a bit of data cleaning to bring the data in a format that will allow us to extract easily all the information we need.\n",
    "\n",
    "\n",
    "Essentialy, we want to bring data to this format:\n",
    "\n",
    "![img](cpgp_dataset_3.png)\n",
    "\n",
    "\n",
    "### Letter Case and Punctuation\n",
    "\n",
    "We'll begin with removing all the punctuation and bringing every letter to lower case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok. But i finish at 6.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>87077: Kick off a new season with 2wks FREE go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ron say fri leh. N he said ding tai feng cant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>Do you want a new Video phone? 600 anytime any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I prefer my free days... Tues, wed, fri oso ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                             Ok. But i finish at 6.\n",
       "1  spam  87077: Kick off a new season with 2wks FREE go...\n",
       "2   ham  Ron say fri leh. N he said ding tai feng cant ...\n",
       "3  spam  Do you want a new Video phone? 600 anytime any...\n",
       "4   ham  I prefer my free days... Tues, wed, fri oso ca..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Before cleaning\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>ok  but i finish at 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>87077  kick off a new season with 2wks free go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>ron say fri leh  n he said ding tai feng cant ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>do you want a new video phone  600 anytime any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>i prefer my free days    tues  wed  fri oso ca...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham                             ok  but i finish at 6 \n",
       "1  spam  87077  kick off a new season with 2wks free go...\n",
       "2   ham  ron say fri leh  n he said ding tai feng cant ...\n",
       "3  spam  do you want a new video phone  600 anytime any...\n",
       "4   ham  i prefer my free days    tues  wed  fri oso ca..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After cleaning\n",
    "training_set['SMS'] = training_set['SMS'].str.replace('\\W', ' ', regex=True)\n",
    "training_set['SMS'] = training_set['SMS'].str.lower()\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Vocabulary\n",
    "\n",
    "Let's now move to creating the vocabulary, which in this context means a list with all the unique words in our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7612"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set['SMS'] = training_set['SMS'].str.split() # transform the SMS column into a list of strings\n",
    "\n",
    "vocabulary = []\n",
    "for sms in training_set['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there are 7,612 unique words in all the messages of our training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Final Training Set\n",
    "\n",
    "We're now going to use the vocabulary we just created to make the data transformation we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a dictionary in which each word in vocabulary is set to 0 for each SMS\n",
    "word_counts_per_sms = {unique_word: [0] * len(training_set['SMS']) for unique_word in vocabulary} # creating a dictionary for our dataframe\n",
    "\n",
    "for index, sms in enumerate(training_set['SMS']):\n",
    "    for word in sms:\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>areyouunique</th>\n",
       "      <th>ths</th>\n",
       "      <th>plenty</th>\n",
       "      <th>attending</th>\n",
       "      <th>buff</th>\n",
       "      <th>2years</th>\n",
       "      <th>reltnship</th>\n",
       "      <th>aight</th>\n",
       "      <th>petrol</th>\n",
       "      <th>strips</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>december</th>\n",
       "      <th>planning</th>\n",
       "      <th>sha</th>\n",
       "      <th>spoon</th>\n",
       "      <th>whats</th>\n",
       "      <th>2p</th>\n",
       "      <th>easier</th>\n",
       "      <th>09111030116</th>\n",
       "      <th>billy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7612 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   areyouunique  ths  plenty  attending  buff  2years  reltnship  aight  \\\n",
       "0             0    0       0          0     0       0          0      0   \n",
       "1             0    0       0          0     0       0          0      0   \n",
       "2             0    0       0          0     0       0          0      0   \n",
       "3             0    0       0          0     0       0          0      0   \n",
       "4             0    0       0          0     0       0          0      0   \n",
       "\n",
       "   petrol  strips  ...  key  december  planning  sha  spoon  whats  2p  \\\n",
       "0       0       0  ...    0         0         0    0      0      0   0   \n",
       "1       0       0  ...    0         0         0    0      0      0   0   \n",
       "2       0       0  ...    0         0         0    0      0      0   0   \n",
       "3       0       0  ...    0         0         0    0      0      0   0   \n",
       "4       0       0  ...    0         0         0    0      0      0   0   \n",
       "\n",
       "   easier  09111030116  billy  \n",
       "0       0            0      0  \n",
       "1       0            0      0  \n",
       "2       0            0      0  \n",
       "3       0            0      0  \n",
       "4       0            0      0  \n",
       "\n",
       "[5 rows x 7612 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome, we're now going to merge our vocabulary dictionary with our training_set data to form the dataframe we seek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>areyouunique</th>\n",
       "      <th>ths</th>\n",
       "      <th>plenty</th>\n",
       "      <th>attending</th>\n",
       "      <th>buff</th>\n",
       "      <th>2years</th>\n",
       "      <th>reltnship</th>\n",
       "      <th>aight</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>december</th>\n",
       "      <th>planning</th>\n",
       "      <th>sha</th>\n",
       "      <th>spoon</th>\n",
       "      <th>whats</th>\n",
       "      <th>2p</th>\n",
       "      <th>easier</th>\n",
       "      <th>09111030116</th>\n",
       "      <th>billy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ok, but, i, finish, at, 6]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>[87077, kick, off, a, new, season, with, 2wks,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[ron, say, fri, leh, n, he, said, ding, tai, f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>[do, you, want, a, new, video, phone, 600, any...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, prefer, my, free, days, tues, wed, fri, os...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  areyouunique  ths  \\\n",
       "0   ham                        [ok, but, i, finish, at, 6]             0    0   \n",
       "1  spam  [87077, kick, off, a, new, season, with, 2wks,...             0    0   \n",
       "2   ham  [ron, say, fri, leh, n, he, said, ding, tai, f...             0    0   \n",
       "3  spam  [do, you, want, a, new, video, phone, 600, any...             0    0   \n",
       "4   ham  [i, prefer, my, free, days, tues, wed, fri, os...             0    0   \n",
       "\n",
       "   plenty  attending  buff  2years  reltnship  aight  ...  key  december  \\\n",
       "0       0          0     0       0          0      0  ...    0         0   \n",
       "1       0          0     0       0          0      0  ...    0         0   \n",
       "2       0          0     0       0          0      0  ...    0         0   \n",
       "3       0          0     0       0          0      0  ...    0         0   \n",
       "4       0          0     0       0          0      0  ...    0         0   \n",
       "\n",
       "   planning  sha  spoon  whats  2p  easier  09111030116  billy  \n",
       "0         0    0      0      0   0       0            0      0  \n",
       "1         0    0      0      0   0       0            0      0  \n",
       "2         0    0      0      0   0       0            0      0  \n",
       "3         0    0      0      0   0       0            0      0  \n",
       "4         0    0      0      0   0       0            0      0  \n",
       "\n",
       "[5 rows x 7614 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_clean = pd.concat([training_set, word_counts], axis=1)\n",
    "training_set_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Constants First\n",
    "\n",
    "We're now done with cleaning the training set, and we can begin creating the spam filter. The Naive Bayes algorithm will need to answer these two probability questions to be able to classify new messages:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Spam | w_1,w_2, ..., w_n) \\propto P(Spam) \\cdot \\prod_{i=1}^{n}P(w_i|Spam)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Ham | w_1,w_2, ..., w_n) \\propto P(Ham) \\cdot \\prod_{i=1}^{n}P(w_i|Ham)\n",
    "\\end{equation*}\n",
    "\n",
    "Also, to calculate P(w<sub>i</sub>|Spam) and P(w<sub>i</sub>|Ham) inside the formulas above, we'll need to use these equations:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation*}\n",
    "\n",
    "The terms in the two equations above mean:\n",
    "\n",
    "- $N_{w_i|Spam} = $ the number of times the word $w_i$ occurs in spam messages\n",
    "- $N_{w_i|ham} = $ the number of times the word $w_i$ occurs in ham messages\n",
    "- $N_{Spam} = $ total number of words in spam messages\n",
    "- $N_{ham} = $ total number of words in ham messages\n",
    "- $N_{Vocabulary} = $ total number of words in the vocabulary\n",
    "- $\\alpha = 1$ ($\\alpha$ is the Laplace smoothing operator)\n",
    "\n",
    "\n",
    "\n",
    "Some of the terms in the four equations above will have the same value for every new message. We can calculate the value of these terms once and avoid doing the computations again when a new messages comes in. Below, we'll use our training set to calculate:\n",
    "\n",
    "- P(Spam) and P(Ham)\n",
    "- N<sub>Spam</sub>, N<sub>Ham</sub>, N<sub>Vocabulary</sub>\n",
    "- and set $\\alpha = 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating spam and ham messages first\n",
    "spam_messages = training_set_clean[training_set_clean['Label'] == 'spam']\n",
    "ham_messages = training_set_clean[training_set_clean['Label'] == 'ham']\n",
    "\n",
    "# P(Spam) and P(Ham)\n",
    "p_spam = len(spam_messages) / len(training_set_clean)\n",
    "p_ham = len(ham_messages) / len(training_set_clean)\n",
    "\n",
    "# N_Spam\n",
    "n_words_per_spam_message = spam_messages['SMS'].apply(len)\n",
    "n_spam = n_words_per_spam_message.sum()\n",
    "\n",
    "# N_Ham\n",
    "n_words_per_ham_message = ham_messages['SMS'].apply(len)\n",
    "n_ham = n_words_per_ham_message.sum()\n",
    "\n",
    "# N_Vocabulary\n",
    "n_vocabulary = len(vocabulary)\n",
    "\n",
    "# Laplace smoothing\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Parameters\n",
    "\n",
    "Now that we have the constant terms calculated above, we can move on with calculating the parameters $P(w_i|Spam)$ and $P(w_i|Ham)$. Each parameter will thus be a conditional probability value associated with each word in the vocabulary.\n",
    "\n",
    "The parameters are calculated using the formulas:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i|Spam) = \\frac{N_{w_i|Spam} + \\alpha}{N_{Spam} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "P(w_i|Ham) = \\frac{N_{w_i|Ham} + \\alpha}{N_{Ham} + \\alpha \\cdot N_{Vocabulary}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate parameters\n",
    "parameters_spam = {unique_word:0 for unique_word in vocabulary}\n",
    "parameters_ham = {unique_word:0 for unique_word in vocabulary}\n",
    "\n",
    "# Calculate parameters\n",
    "for word in vocabulary:\n",
    "    n_word_given_spam = spam_messages[word].sum()   # spam_messages already defined in a cell above\n",
    "    p_word_given_spam = (n_word_given_spam + alpha) / (n_spam + alpha*n_vocabulary)\n",
    "    parameters_spam[word] = p_word_given_spam\n",
    "    \n",
    "    n_word_given_ham = ham_messages[word].sum()   # ham_messages already defined in a cell above\n",
    "    p_word_given_ham = (n_word_given_ham + alpha) / (n_ham + alpha*n_vocabulary)\n",
    "    parameters_ham[word] = p_word_given_ham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying A New Message\n",
    "\n",
    "Now that we have all our parameters calculated, we can start creating the spam filter. The spam filter can be understood as a function that:\n",
    "\n",
    "- Takes in as input a new message (w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>).\n",
    "- Calculates P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>).\n",
    "- Compares the values of P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) and P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), and:\n",
    "    - If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) > P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as ham.\n",
    "    - If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) < P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the message is classified as spam.\n",
    "    -  If P(Ham|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>) = P(Spam|w<sub>1</sub>, w<sub>2</sub>, ..., w<sub>n</sub>), then the algorithm may request human help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def classify(message):\n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "            \n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the classify function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 8.127042930442235e-26\n",
      "P(Ham|message): 1.0997819762771794e-27\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 3.280733215371128e-25\n",
      "P(Ham|message): 3.7255583099559524e-21\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring the Spam Filter's Accuracy\n",
    "\n",
    "The two results above look promising, but let's see how well the filter does on our test set, which has 1,114 messages.\n",
    "\n",
    "We'll start by writing a function that returns classification labels instead of printing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_set(message):    \n",
    "    '''\n",
    "    message: a string\n",
    "    '''\n",
    "    \n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in parameters_spam:\n",
    "            p_spam_given_message *= parameters_spam[word]\n",
    "            \n",
    "        if word in parameters_ham:\n",
    "            p_ham_given_message *= parameters_ham[word]\n",
    "    \n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a function that returns labels instead of printing them, we can use it to create a new column in our test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nothing, i got msg frm tht unknown no..</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Jason says it's cool if we pick some up from h...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Call me when u're done...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well there's not a lot of things happening in ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I was about to do it when i texted. I finished...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham            Nothing, i got msg frm tht unknown no..       ham\n",
       "1   ham  Jason says it's cool if we pick some up from h...       ham\n",
       "2   ham                          Call me when u're done...       ham\n",
       "3   ham  Well there's not a lot of things happening in ...       ham\n",
       "4   ham  I was about to do it when i texted. I finished...       ham"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set['predicted'] = test_set['SMS'].apply(classify_test_set)\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll write a function to measure the accuracy of our spam filter to find out how well our spam filter does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1018\n",
      "Incorrect: 16\n",
      "Accuracy: 0.9845261121856866\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = test_set.shape[0]\n",
    "\n",
    "result = (test_set['Label'] == test_set['predicted'])\n",
    "correct = result.sum()\n",
    "    \n",
    "# for row in test_set.iterrows():\n",
    "#     row = row[1]\n",
    "#     if row['Label'] == row['predicted']:\n",
    "#         correct += 1\n",
    "        \n",
    "print('Correct:', correct)\n",
    "print('Incorrect:', total - correct)\n",
    "print('Accuracy:', correct/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is close to 98.45%, which is really good. Our spam filter looked at 1,114 messages that it hasn't seen in training, and classified 1,018 correctly.\n",
    "\n",
    "Let's look at the 16 messages the spam filter got wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>26th OF JULY</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>spam</td>\n",
       "      <td>In The Simpsons Movie released in July 2007 na...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hello darling how are you today? I would love ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>ham</td>\n",
       "      <td>Mathews or tait or edwards or anderson</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>spam</td>\n",
       "      <td>thesmszone.com lets you send free anonymous an...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi I'm sue. I am 20 years old and work as a la...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>649</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi its LUCY Hubby at meetins all day Fri &amp; I w...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>ham</td>\n",
       "      <td>Finally the match heading towards draw as your...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>ham</td>\n",
       "      <td>Waiting for your call.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>spam</td>\n",
       "      <td>INTERFLORA - Â“It's not too late to order Inter...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>spam</td>\n",
       "      <td>You won't believe it but it's true. It's Incre...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>spam</td>\n",
       "      <td>More people are dogging in your area now. Call...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>spam</td>\n",
       "      <td>Latest News! Police station toilet stolen, cop...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>spam</td>\n",
       "      <td>Your next amazing xxx PICSFREE1 video will be ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1031</th>\n",
       "      <td>spam</td>\n",
       "      <td>accordingly. I repeat, just text the word ok o...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS predicted\n",
       "22     ham                                       26th OF JULY      spam\n",
       "142   spam  In The Simpsons Movie released in July 2007 na...       ham\n",
       "148   spam  Hello darling how are you today? I would love ...       ham\n",
       "282    ham             Mathews or tait or edwards or anderson      spam\n",
       "315   spam  thesmszone.com lets you send free anonymous an...       ham\n",
       "407   spam  Hi I'm sue. I am 20 years old and work as a la...       ham\n",
       "649   spam  Hi its LUCY Hubby at meetins all day Fri & I w...       ham\n",
       "685   spam  Hi babe its Chloe, how r u? I was smashed on s...       ham\n",
       "732    ham  Finally the match heading towards draw as your...      spam\n",
       "744    ham                             Waiting for your call.      spam\n",
       "865   spam  INTERFLORA - Â“It's not too late to order Inter...       ham\n",
       "870   spam  You won't believe it but it's true. It's Incre...       ham\n",
       "914   spam  More people are dogging in your area now. Call...       ham\n",
       "921   spam  Latest News! Police station toilet stolen, cop...       ham\n",
       "925   spam  Your next amazing xxx PICSFREE1 video will be ...       ham\n",
       "1031  spam  accordingly. I repeat, just text the word ok o...       ham"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_classify_sms = test_set[test_set['Label'] != test_set['predicted']]\n",
    "wrong_classify_sms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe short messages and other messages are mixed in with characters that weren't cleaned properly. Why were those messages wrongly classified? We may ask. A possible solution is that some words occur only in one category (say one word in spam, and another in ham) and not the other. Another reason could be that the spammers got clever and figured out how to beat the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "In this project, we managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter had an accuracy of 98.45% on the test set we used, which is a pretty good result. Our initial goal was an accuracy of over 80%, and we managed to do way better than that. We analysed the 16 messages that the algorithm classified them incorrectly and came to a conclusion that the situation out of our hands. As with some spam message the sender was clever and got around the algorithm. Other messages is all about improving the algorithm.\n",
    "\n",
    "Next step, we will build the SMS spam filter classifier using the scikit-learn library as it's what we would use in real-life in order to be more productive. We'll then compare the results with the one here. See you there."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "61ad20634e5b30473fd3590a4a237acec9deb4824a9bccab87938fafc7e6477e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
